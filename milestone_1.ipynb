{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization : milestone 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we found interesting to take a record of some of the 911 calls in Montgomery County, in the Commonwealth of Pennsylvania.\n",
    "\n",
    "You can find the data set here : https://www.kaggle.com/datasets/mchirico/montcoalert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = {\"calls\": \"./input/archive.zip\", \"revenues\":\"./input/montgomery_county_revenues.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "calls_data = pd.read_csv(\n",
    "    filepath_or_buffer = FILE_LOCATION[\"calls\"],\n",
    "    header = 0,\n",
    "    names = ['lat', 'lng', 'desc', 'zip', 'title', 'timeStamp', 'twp', 'addr', 'e'],\n",
    "    dtype = {\n",
    "        'lat':str,'lng':str,'desc':str, 'zip':str,\n",
    "        'title':str, 'timeStamp':str, 'twp':str, 'addr':str, 'e':int\n",
    "        }, \n",
    "    parse_dates = ['timeStamp'],\n",
    "    date_parser = dateparse)\n",
    "\n",
    "calls_data.timeStamp = pd.DatetimeIndex(calls_data.timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a first look, the data set seems realtively clean. There could be some NaN on the zip information or other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues_data = pd.read_csv(\n",
    "    filepath_or_buffer = FILE_LOCATION[\"revenues\"],\n",
    "    header = 0,\n",
    "    names = ['zipcode', 'med_revenue'],\n",
    "    dtype = {'zipcode': str, 'med_revenue': \"Int64\"},\n",
    "    sep = \";\",\n",
    "    na_values = \"Nothing\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First look at the calls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expect for the zip column, all the others columns do not contain any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description column must be pretty unique. Let us check if there is any duplicates on that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(calls_data['desc'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"percentage of duplicates dropped in the description column :\", (1 - len(calls_data['desc'].drop_duplicates()) / len(calls_data))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column does not seem to have loads (less than 1%) of duplicates values. It is important since it contains lots of valuable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set seems relatively big enough to perfom some interesting vizualizations. \n",
    "\n",
    "It do not contain a major number of duplicates or missing values on important column, so the cleaning / pre-processing part will not be very difficult to tackle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data = calls_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates in the description column\n",
    "clean_calls_data = calls_data.drop_duplicates(\"desc\")\n",
    "\n",
    "# Drop the NA's\n",
    "clean_calls_data = clean_calls_data.dropna()\n",
    "\n",
    "# Create a new group column for each main category (EMS / Traffic / Fire) of the title column \n",
    "clean_calls_data['group'] = clean_calls_data['title'].apply(lambda x: x.split(':')[0])\n",
    "\n",
    "# Create a year column for time series plots\n",
    "clean_calls_data[\"year\"] = clean_calls_data['timeStamp'].dt.year\n",
    "\n",
    "clean_calls_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the zip codes and the map, there are some outliers to the data set (c.f. zip codes of Montgomery County, Pennsylvania : https://www.ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?FIPS=42091) : it does not contain zip codes that are starting with the number 17.\n",
    "\n",
    "It could be that some calls are outside of the county and the emergency services went outside of the county.\n",
    "\n",
    "We decided to focus more on the county and less of these \"outliers\".\n",
    "\n",
    "Let us filter these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data['zip_initial'] = clean_calls_data['zip'].str[:2]\n",
    "\n",
    "clean_calls_data['zip_initial'] = pd.to_numeric(clean_calls_data['zip_initial'])\n",
    "\n",
    "clean_calls_data = clean_calls_data.query('zip_initial >= 18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_calls_per_year = clean_calls_data.groupby('year')['e'].agg(['count'])\n",
    "\n",
    "n_calls_per_year = pd.DataFrame(n_calls_per_year).reset_index()\n",
    "\n",
    "n_calls_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = n_calls_per_year, x = 'year', y = 'count')\n",
    "plt.title('Number of calls per year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make sense to start the data from 2016 on, since it does not contain loads of data. \n",
    "\n",
    "For the decline in 2020, we could remove some of the months since the slope seems less important than the one from 2015-2016, but let us first analyze those years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data = clean_calls_data[(clean_calls_data.timeStamp >= \"2016-01-01 00:00:00\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the 2020 year have much less 911 calls than the other years. Could that be because another event (like COVID for example) or is it because the data set is incomplete ? (or both) \n",
    "\n",
    "Let us take a deeper look at the 2019 and 2020 year, specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_19 = clean_calls_data.query('year >= 2019 ')\n",
    "\n",
    "calls_19['month_year'] = calls_19['timeStamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
    "\n",
    "# Create a pivot table to count the calls per week\n",
    "calls_pivot = pd.pivot_table(calls_19, values='e', index=['timeStamp'], columns=['group'], aggfunc=np.sum)\n",
    "\n",
    "# Creating counts per group per week\n",
    "calls_pivot = calls_pivot.resample('W').agg(np.sum).reset_index()\n",
    "calls_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left() \n",
    "plt.xticks(fontsize = 12) \n",
    "\n",
    "ax.plot_date(calls_pivot['timeStamp'], calls_pivot['EMS'],'k', label = 'EMS')\n",
    "ax.plot_date(calls_pivot['timeStamp'], calls_pivot['Traffic'],'b', label = 'Traffic')\n",
    "ax.plot_date(calls_pivot['timeStamp'], calls_pivot['Fire'],'r', label = 'Fire')\n",
    "\n",
    "\n",
    "ax.set_title(\"EMS, Fire and Traffic 911 calls for the 2019 - 2020 years\")\n",
    "fig.autofmt_xdate()\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe two things: \n",
    "\n",
    "- The data set stops at august 2020, not as the other years as they are complete. The 2020 year has 4 months of calls missing compared to the other years.\n",
    "\n",
    "- There is a decrease in the calls around march-april 2020 ; it could be correlated with the COVID-19 crisis but further researches to support that hypothesis must be done.\n",
    "\n",
    "We should remove the end months of 2020, since after the decrease there seems to be a significant increase in calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_pivot_20 = calls_pivot[(calls_pivot.timeStamp >= \"2020-01-01 00:00:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left() \n",
    "plt.xticks(fontsize=12) \n",
    "\n",
    "ax.plot_date(calls_pivot_20['timeStamp'], calls_pivot_20['EMS'], 'k', label = 'EMS')\n",
    "ax.plot_date(calls_pivot_20['timeStamp'], calls_pivot_20['Traffic'], 'b', label = 'Traffic')\n",
    "ax.plot_date(calls_pivot_20['timeStamp'], calls_pivot_20['Fire'], 'r', label = 'Fire')\n",
    "\n",
    "\n",
    "ax.set_title(\"EMS, Fire and Traffic 911 calls for the 2020 year\")\n",
    "fig.autofmt_xdate()\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems reasonable to cut July and August of the time frame for the 2020 year, which contains much less data than the other months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_august = calls_pivot_20[(calls_pivot_20.timeStamp > \"2020-06-28 00:00:00\")]\n",
    "\n",
    "july_august"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data = clean_calls_data[(clean_calls_data.timeStamp <= \"2020-06-28 00:00:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data['month_year'] = clean_calls_data['timeStamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
    "\n",
    "# Create a pivot table to count the calls per week\n",
    "clean_calls_pivot = pd.pivot_table(clean_calls_data, values='e', index=['timeStamp'], columns=['group'], aggfunc=np.sum)\n",
    "\n",
    "# Creating counts per group per week\n",
    "clean_calls_pivot = clean_calls_pivot.resample('W').agg(np.sum).reset_index()\n",
    "clean_calls_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left() \n",
    "plt.xticks(fontsize = 12) \n",
    "\n",
    "ax.plot_date(clean_calls_pivot['timeStamp'], clean_calls_pivot['EMS'],'k', label = 'EMS')\n",
    "ax.plot_date(clean_calls_pivot['timeStamp'], clean_calls_pivot['Traffic'],'b', label = 'Traffic')\n",
    "ax.plot_date(clean_calls_pivot['timeStamp'], clean_calls_pivot['Fire'],'r', label = 'Fire')\n",
    "\n",
    "\n",
    "ax.set_title(\"EMS, Fire and Traffic 911 calls from 2016 - 2020\")\n",
    "fig.autofmt_xdate()\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the revenues data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We miss 9 revenue values. Except that, we have access to the median revenue of each zipcode present in the calls dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable further work, we will approximate the missing revenues as the average of all the other revenues. This approach is definitely questionable, but it just a first approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_med_revenue = revenues_data[revenues_data[\"med_revenue\"].notnull()][\"med_revenue\"].mean()\n",
    "clean_revenues_data = revenues_data\n",
    "clean_revenues_data[\"med_revenue\"] = revenues_data[\"med_revenue\"].fillna(int(average_med_revenue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin with vizualizing just simple counts of the values in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data[\"title\"].value_counts()[:20].plot(kind = \"barh\")\n",
    "plt.title('20 most common 911 calls in Montgomery County, PA for the 2016-2020 period')\n",
    "plt.xlabel('Number of 911 calls')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic problems have the most calls over the years, followed by fire alarm accidents and fall victim emergencies.\n",
    "\n",
    "Vehicle accidents surpass the others by far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calls_data[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that EMS (Emergency medical services) are the highest number of the calls made in the county, followed by traffic and fire.\n",
    "\n",
    "Although, it seems that it is because Traffic only have few titles compared to the EMS one, that is categorize into more several titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calls per time of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot a heatmap of the most common call type and see how it evolve depending on the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_accidents = clean_calls_data[(clean_calls_data.title.str.match(r'EMS:.*VEHICLE ACCIDENT.*') | clean_calls_data.title.str.match(r'Traffic:.*VEHICLE ACCIDENT.*'))]\n",
    "\n",
    "vehicle_accidents['Month'] = vehicle_accidents['timeStamp'].apply(lambda x: x.strftime('%m %B'))\n",
    "vehicle_accidents['Hour'] = vehicle_accidents['timeStamp'].apply(lambda x: x.strftime('%H'))\n",
    "\n",
    "pivot_table_accidents = pd.pivot_table(vehicle_accidents, values='e', index=['Month'] , columns=['Hour'], aggfunc=np.sum)\n",
    "\n",
    "pivot_table_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.cubehelix_palette(light = 2, as_cmap = True)\n",
    "\n",
    "ax = sns.heatmap(pivot_table_accidents, cmap = cmap)\n",
    "\n",
    "ax.set_title('Vehicle Accidents during the period 2016-2020, over all townships in Montgomery County, PA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that most of the vehicle accidents are during november / december / january, especially at 5 pm.\n",
    "\n",
    "It could be because it is the end of the day so people are more tired and focused than the beginning of the day; it corresponds fairly to the end of the working time, people could be tired and want to go home rather quickly.\n",
    "\n",
    "It could also be because during winter there is less visibilty on the road or more severe weather than during the spring or summer.\n",
    "\n",
    "Sun goes down at approximatively 4.30 pm during the winter, in december (c.f. https://www.timeanddate.com/sun/@5201756?month=12&year=2019), which could explain more accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calls per regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = clean_calls_data.copy()\n",
    "\n",
    "sorted_regions = regions.groupby('zip')['e'].agg(['count']).sort_values('count', ascending = False)\n",
    "\n",
    "sorted_regions = pd.DataFrame(sorted_regions).reset_index()\n",
    "\n",
    "sorted_regions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clearly seems that there are \"hotspots\" for calls in the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/pa_pennsylvania_zip_codes_geo.min.json') as response:\n",
    "    zipcodes = json.load(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    data_frame = sorted_regions, \n",
    "    geojson = zipcodes,\n",
    "    locations = 'zip', \n",
    "    color = 'count',\n",
    "    featureidkey = \"properties.ZCTA5CE10\",\n",
    "    labels = {\"count\": \"number of calls\"}\n",
    ")\n",
    "fig.update_layout(margin = {\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.update_geos(fitbounds = \"locations\", visible = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_regions_grouped = clean_calls_data.groupby(['zip', 'group'])['e'].agg(['count']).sort_values('count', ascending=False)\n",
    "\n",
    "sorted_regions_grouped = pd.DataFrame(sorted_regions_grouped).reset_index()\n",
    "\n",
    "sorted_regions_grouped.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    data_frame = clean_revenues_data, \n",
    "    geojson = zipcodes,\n",
    "    locations = 'zipcode', \n",
    "    color = 'med_revenue',\n",
    "    featureidkey = \"properties.ZCTA5CE10\",\n",
    "    labels = {\"med_revenue\": \"median revenue($)\"}\n",
    ")\n",
    "fig.update_layout(margin = {\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n",
    "fig.update_geos(fitbounds = \"locations\", visible = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87259b15c3afccf059722440ab90a1874d985996384e98fcc7aa5e93528035d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
